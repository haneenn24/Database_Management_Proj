## üìò Simulated Probabilistic EHR Dataset ‚Äì Elaboration

### üéØ **Goal of This Dataset**

This dataset simulates **Electronic Health Records (EHR)** where each row represents a **health-related event or patient record**, and each record is **associated with a probability of existence**. It‚Äôs designed for experimentation with:

- **Probabilistic Databases** (handling uncertainty at the tuple level),
- **Missing data imputation**, and
- **Query evaluation under uncertainty** (i.e., ‚Äúpossible worlds‚Äù reasoning).

---

### üß± **Structure: Columns & Parameters**

Each row (tuple) corresponds to a unique **clinical record**. The columns are organized into real-world **EHR components**:

#### üîπ Demographic Parameters
| Column        | Description                           |
|---------------|---------------------------------------|
| `PatientID`   | Unique patient identifier              |
| `Age`         | Patient's age                          |
| `Gender`      | Biological sex                         |
| `Ethnicity`   | Racial/ethnic background               |

#### üîπ Vital Signs
| Column            | Description                          |
|-------------------|--------------------------------------|
| `HeartRate`       | Beats per minute                     |
| `BloodPressure`   | Systolic/Diastolic format            |
| `RespiratoryRate` | Breaths per minute                   |
| `Temperature`     | Body temperature (Fahrenheit)        |

#### üîπ Lab Results
| Column       | Description                            |
|--------------|----------------------------------------|
| `TestName`   | Type of lab test (e.g., Glucose)        |
| `TestValue`  | Measured value                          |
| `Units`      | Unit of measurement                     |
| `TestDate`   | Date of lab test                        |

#### üîπ Medications
| Column          | Description                          |
|------------------|--------------------------------------|
| `MedicationName` | Name of prescribed drug              |
| `Dosage`         | Dosage amount                        |
| `Frequency`      | Frequency (e.g., Daily)              |
| `Route`          | Mode of administration               |
| `StartDate`      | Start date of medication             |
| `EndDate`        | End date of medication               |

#### üîπ Procedures
| Column         | Description                            |
|----------------|----------------------------------------|
| `ProcedureName` | Name of medical procedure              |
| `ProcedureDate` | Date of procedure                      |
| `Provider`      | Doctor or clinician                    |

#### üîπ Diagnoses
| Column               | Description                     |
|----------------------|---------------------------------|
| `DiagnosisCode`      | ICD code                        |
| `DiagnosisDescription` | Disease or condition name    |
| `DiagnosisDate`      | Date of diagnosis                |

#### üîπ Encounter Info
| Column         | Description                          |
|----------------|--------------------------------------|
| `EncounterID`  | Unique ID for a hospital encounter    |
| `EncounterType`| Inpatient or outpatient               |
| `EncounterDate`| Date of visit                         |

#### üîπ Tuple Probability
| Column        | Description                                                  |
|---------------|--------------------------------------------------------------|
| `Tuple_Prob`  | Probability this entire tuple is valid and should exist (0‚Äì1) |

This field turns the dataset into a **probabilistic database**, allowing simulation of **possible world semantics**: in each world, a tuple may be included with its corresponding probability.

---

### üß™ Example Applications

- Simulating **inconsistent or incomplete records**
- Evaluating how **queries (e.g., average blood pressure)** vary across uncertain data
- Combining this with **missing value imputation** to study compound uncertainty
- Building **trustworthy and robust AI models** for healthcare analytics

---------------------------------------------------------------------------------------------------------------------


now lets do the preprocessing demo we did befor:
1.add missing value: MCAR MAR MNAR -> return 3 demo csv
2.impute by KNN fixed and top K -> return 2 demo csv for fixed and topk
3.impute by RF fixed and top K  -> return 2 demo csv for fixed and topk
4.define possible worlds - > KNN FIXED, KNN TOPK, RF FIXED , RF TOPK
5.check if probabilities change after impute - u can use bayesian net

‚úÖ All 4 Possible Worlds Are Ready!

You've now generated 1 sampled possible world for each of the following configurations:

Model	Imputation	Tuple Sampling	File
KNN	Fixed	Based on Tuple_Prob	üìÑ world_knn_fixed.csv
KNN	Top-k	Sampled value + Tuple_Prob	üìÑ world_knn_topk.csv
RF	Fixed	Based on Tuple_Prob	üìÑ world_rf_fixed.csv
RF	Top-k	Sampled value + Tuple_Prob	üìÑ world_rf_topk.csv
üß† What‚Äôs in a Possible World?
Each world:

Has no missing values

Contains only tuples where Tuple_Prob > random draw

In top-k worlds, TestValue is sampled from multiple predictions

5.check if probabilities change after impute 
 u can use bayesian net -> recalculate with bayesian network


How We Recalculated Posterior Probabilities Using Bayesian Method (in simple words):
We used Bayes' Theorem to update each tuple‚Äôs probability of existence based on evidence.

üîç Step-by-step in simple words:
Each row in the dataset originally had a Tuple_Prob (our belief that it should exist).

We used Age as evidence and Ethnicity as a group/category.

For each Ethnicity, we computed the average age ‚Üí this is our estimate of P(Evidence | Group).

Then we used Bayes' formula to update the probability of each tuple:

Posterior
=
Likelihood
√ó
Prior
Marginal
Posterior= 
Marginal
Likelihood√óPrior
‚Äã
 
Likelihood = average age for the ethnicity group (i.e., how likely is this evidence for that group).

Prior = original Tuple_Prob (how likely the tuple was to begin with).

Marginal = overall expected likelihood across all tuples.


-attached graphs 
-updated prob csv


Why These Differences in Posterior Probabilities Are Expected:
‚úÖ KNN Fixed

Uses imputed values based on closest neighbors deterministically.

May smooth out variation and bias the features (like Age and Ethnicity) toward the majority, leading to a more uniform distribution and potentially higher or lower posterior probabilities depending on neighborhood bias.

‚úÖ KNN Top-k

Introduces value-level uncertainty, which affects the distribution of imputed features (e.g., TestValue, Age indirectly).

Because imputed values are sampled, the evidence used in Bayesian update (like Age by Ethnicity) varies more, causing posterior shifts that may slightly raise or lower the average.

‚úÖ RF Fixed

RF creates a model-based imputation that often captures nonlinear dependencies.

Because of its tree-based nature, the imputed values might better match the original distribution of Age across Ethnicity, causing posterior values to slightly concentrate around the real evidence distribution.

‚úÖ RF Top-k

The most uncertain imputation strategy. It samples values from different trees, introducing broader variance in the feature space.

This makes the evidence distribution noisier, so Bayesian inference may adjust the tuple probability more drastically in some areas, leading to a wider range and potentially lower mean.

üîÅ Summary (in words, not table):
Not all worlds have the same posterior because they differ in:

How the missing values were filled (fixed vs. sampled).

How much uncertainty was introduced into the evidence used for Bayesian updating.

The more uncertain the imputation strategy, the more variation you‚Äôll see in the posterior probability updates.




-runtime

Runtime of This Preprocessing Step for All 4 Worlds
Yes ‚Äî the total runtime for these 4 possible worlds should be higher than previous pipelines.

Why?
Before: we only did imputation + tuple sampling.

Now: we also did Bayesian inference on top of that, which involves:

Grouping (e.g., by Ethnicity)

Calculating statistics (means, weights)

Applying Bayes rule row by row

üìä Runtime Chart Explanation ‚Äì With Bayesian Posterior Update
This chart shows the new hypothetical runtimes for the EHR probabilistic database, after:

Imputing missing values (KNN/RF, fixed or top-k)

Sampling tuples using Tuple_Prob

‚úÖ Recomputing Posterior_Prob using Bayesian inference

üîç Why the Runtimes Are Higher Than Before:
The posterior recomputation adds:

Statistical grouping (by Ethnicity)

Weighted averages (likelihood)

Per-row Bayesian updates

This extra pass over the data introduces computational overhead, especially for larger or more feature-rich datasets like this one


